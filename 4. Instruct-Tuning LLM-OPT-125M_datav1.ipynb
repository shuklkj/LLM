{"cells":[{"cell_type":"markdown","id":"8637efd2-9670-4ee4-9801-8140b433e98c","metadata":{"id":"8637efd2-9670-4ee4-9801-8140b433e98c"},"source":["# Final Project\n","## ADSP 32021 IP01 Machine Learning Operations\n","### 4. Instruct-Tuning LLM\n","#### Group 2: Maria Clarissa Fionalita, Kajal Shukla, Mia Zhang, Priya Suvvaru Venkata"]},{"cell_type":"code","execution_count":null,"id":"c4f6cd6d-2767-4ac6-bbbf-8e770d339726","metadata":{"tags":[],"id":"c4f6cd6d-2767-4ac6-bbbf-8e770d339726","outputId":"2963871e-aeba-4537-8c80-b68014cd3517"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.10.13\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":null,"id":"5dbd6084-986d-4c8f-822e-9e6a396fbdf1","metadata":{"tags":[],"id":"5dbd6084-986d-4c8f-822e-9e6a396fbdf1"},"outputs":[],"source":["import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""]},{"cell_type":"code","execution_count":null,"id":"cc5571be-3eb2-4226-ba0b-bb7d9c458c79","metadata":{"tags":[],"id":"cc5571be-3eb2-4226-ba0b-bb7d9c458c79"},"outputs":[],"source":["# from transformers import logging\n","\n","# logging.set_verbosity_warning()"]},{"cell_type":"code","execution_count":null,"id":"aae855ad-d586-4e7a-a6ac-44ebdfe080c8","metadata":{"id":"aae855ad-d586-4e7a-a6ac-44ebdfe080c8"},"outputs":[],"source":["# from huggingface_hub import notebook_login\n","# # https://huggingface.co/settings/tokens\n","\n","# notebook_login()"]},{"cell_type":"markdown","id":"12b7e8ed-b84e-4c6a-bb51-03bd8d4ef8b0","metadata":{"id":"12b7e8ed-b84e-4c6a-bb51-03bd8d4ef8b0"},"source":["# Load Training Data\n","\n","https://huggingface.co/docs/datasets/loading"]},{"cell_type":"code","execution_count":null,"id":"6e7a26f4-0b63-4c4f-9b5b-feefb94be355","metadata":{"tags":[],"id":"6e7a26f4-0b63-4c4f-9b5b-feefb94be355"},"outputs":[],"source":["import json\n","from pathlib import Path\n","from pprint import pprint\n","\n","import datasets\n","from datasets import load_dataset\n","\n","from transformers import DefaultDataCollator, AutoTokenizer"]},{"cell_type":"code","execution_count":null,"id":"2452cf51-88dc-4215-9111-50b3e89f9162","metadata":{"tags":[],"id":"2452cf51-88dc-4215-9111-50b3e89f9162","outputId":"6392ae2f-f24f-4cb7-b0a4-97ae16e7d7fd","colab":{"referenced_widgets":["133ffa7bd8554db0af1b4515a80ff934","8ad9a50e8af44498986f177db41d6fce","892602b72d65430da0bdd7f1ce859970","abec2f4e31cf4cca8cce1cb30ee3bb0c","87c6f79d99c74f5e93f97f83b6f6ba8a","cc32835e15b842b98bbedc847af48fe2"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"133ffa7bd8554db0af1b4515a80ff934","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ad9a50e8af44498986f177db41d6fce","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/132M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"892602b72d65430da0bdd7f1ce859970","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"abec2f4e31cf4cca8cce1cb30ee3bb0c","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87c6f79d99c74f5e93f97f83b6f6ba8a","version_major":2,"version_minor":0},"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc32835e15b842b98bbedc847af48fe2","version_major":2,"version_minor":0},"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["data_files = {\n","              \"train\": \"gs://capstone-team-green/mlops_data/finetune_data/training_data_v1.json\",\n","              \"validation\": \"gs://capstone-team-green/mlops_data/finetune_data/validation_data_v1.json\",\n","              \"test\": \"gs://capstone-team-green/mlops_data/finetune_data/test_data_v1.json\"\n","    }\n","\n","data = load_dataset(\"json\", data_files = data_files)"]},{"cell_type":"code","execution_count":null,"id":"14bd4a07-830b-4f17-b41c-689368d6532c","metadata":{"tags":[],"id":"14bd4a07-830b-4f17-b41c-689368d6532c","outputId":"1215b0a0-a743-4ce3-f2cf-1768ec9028f7"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['answers_text', 'question', 'id', 'is_impossible', 'answers', 'context', 'url'],\n","        num_rows: 19989\n","    })\n","    validation: Dataset({\n","        features: ['answers_text', 'question', 'id', 'is_impossible', 'answers', 'context', 'url'],\n","        num_rows: 2686\n","    })\n","    test: Dataset({\n","        features: ['answers_text', 'question', 'id', 'is_impossible', 'answers', 'context', 'url'],\n","        num_rows: 2614\n","    })\n","})"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"markdown","id":"e06bf9a1-ac8f-4515-ab52-4551820caaf2","metadata":{"id":"e06bf9a1-ac8f-4515-ab52-4551820caaf2"},"source":["# Training Data Pre-Processing\n","\n","https://huggingface.co/docs/transformers/tasks/question_answering"]},{"cell_type":"markdown","id":"3a33f36f-7ade-4b12-b229-7fce2a6c23b6","metadata":{"id":"3a33f36f-7ade-4b12-b229-7fce2a6c23b6"},"source":["## Load Tokenizer"]},{"cell_type":"code","execution_count":null,"id":"15892640-3162-4790-ae2b-21516a878839","metadata":{"tags":[],"id":"15892640-3162-4790-ae2b-21516a878839","outputId":"e9a5a84b-a2e5-4da4-e8c1-e6da72c3c385"},"outputs":[{"data":{"text/plain":["(True, True)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model_name = \"facebook/opt-125m\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\"\n","tokenizer.add_eos_token = True\n","tokenizer.add_bos_token, tokenizer.add_eos_token"]},{"cell_type":"markdown","id":"0cf5fdb4-5464-48e7-9445-390aa32c3c7e","metadata":{"id":"0cf5fdb4-5464-48e7-9445-390aa32c3c7e"},"source":["## Create a preprocess_function to\n","Tokenize the input text and label\n","\n","[Alpaca LoRA's finetuning method](https://github.com/tloen/alpaca-lora/blob/main/finetune.py)nsors."]},{"cell_type":"code","execution_count":null,"id":"8003d09b-0691-43b2-bbb7-ebaa8db94026","metadata":{"tags":[],"id":"8003d09b-0691-43b2-bbb7-ebaa8db94026"},"outputs":[],"source":["cutoff_len: int = 256\n","\n","def tokenize(prompt, add_eos_token=True):\n","    # there's probably a way to do this with the tokenizer settings\n","    # but again, gotta move fast\n","    result = tokenizer(\n","        prompt,\n","        truncation = True,\n","        max_length = cutoff_len,\n","        padding = \"max_length\",\n","        return_tensors=None,\n","    )\n","    if (\n","        result[\"input_ids\"][-1] != tokenizer.eos_token_id\n","        and len(result[\"input_ids\"]) < cutoff_len\n","        and add_eos_token\n","    ):\n","        result[\"input_ids\"].append(tokenizer.eos_token_id)\n","        result[\"attention_mask\"].append(1)\n","\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","\n","    return result\n","\n","def format_prompt(sample):\n","    prompt = f\"\"\"### Instruction: You are a helpful assistant that can answer medical questions. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\n","\n","    ### Context information is below:\n","    {sample['context']}\n","\n","    ### Given the context information and not prior knowledge, answer the question: {sample['question']}\n","\n","    ### answer: {sample[\"answers_text\"]}\n","    \"\"\"\n","    return prompt\n","\n","def preprocess_function(examples):\n","    full_prompt = format_prompt(examples)\n","\n","    tokenized_full_prompt = tokenize(full_prompt)\n","\n","    return tokenized_full_prompt"]},{"cell_type":"code","execution_count":null,"id":"2d9ffe5d-3fd4-441c-9560-4fb46630b426","metadata":{"tags":[],"id":"2d9ffe5d-3fd4-441c-9560-4fb46630b426","outputId":"dbddec64-8e1d-40d9-ea4e-a0c408693179","colab":{"referenced_widgets":["e0b686daa23d460c8aee0670dae5feba","c1790e893b6b49129dea55f7581dc035"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e0b686daa23d460c8aee0670dae5feba","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/19989 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1790e893b6b49129dea55f7581dc035","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2686 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["CPU times: user 1min 56s, sys: 15.3 s, total: 2min 11s\n","Wall time: 1min 33s\n"]}],"source":["%%time\n","\n","train_data = data[\"train\"].map(preprocess_function, remove_columns=list(data[\"train\"].features))\n","validation_data = data[\"validation\"].map(preprocess_function, remove_columns=list(data[\"validation\"].features))"]},{"cell_type":"code","execution_count":null,"id":"d855b3ec-3fc9-48b5-99e1-641df98e6d4d","metadata":{"tags":[],"id":"d855b3ec-3fc9-48b5-99e1-641df98e6d4d"},"outputs":[],"source":["# create data collator\n","data_collator = DefaultDataCollator()"]},{"cell_type":"code","execution_count":null,"id":"5127e5eb-51f5-4623-ba9d-87d3fd8cb38c","metadata":{"tags":[],"id":"5127e5eb-51f5-4623-ba9d-87d3fd8cb38c","outputId":"c4ff866e-5b0c-493e-8267-6913005e30e3"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 19989\n","})"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# https://discuss.huggingface.co/t/the-model-did-not-return-a-loss-from-the-inputs-only-the-following-keys-logits-for-reference-the-inputs-it-received-are-input-values/25420/9\n","train_data"]},{"cell_type":"markdown","id":"b2c45879-ad6f-4ca9-825e-c46516b0d31d","metadata":{"id":"b2c45879-ad6f-4ca9-825e-c46516b0d31d"},"source":["# Train"]},{"cell_type":"markdown","id":"1bfc81c3-0821-4dc6-8ed6-8e7258dda4ab","metadata":{"id":"1bfc81c3-0821-4dc6-8ed6-8e7258dda4ab"},"source":["## Load OPT-125M"]},{"cell_type":"code","execution_count":null,"id":"a95c76b8-930c-48d3-a839-492740fb4162","metadata":{"tags":[],"id":"a95c76b8-930c-48d3-a839-492740fb4162"},"outputs":[],"source":["import torch\n","from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n","from optimum.bettertransformer import BetterTransformer"]},{"cell_type":"code","execution_count":null,"id":"cabdc7b7-a596-4552-a8b8-ec58af827fb4","metadata":{"tags":[],"id":"cabdc7b7-a596-4552-a8b8-ec58af827fb4"},"outputs":[],"source":["model = AutoModelForCausalLM.from_pretrained(model_name)\n","model.config.use_cache = False"]},{"cell_type":"markdown","id":"a00d8da6-22b8-42b0-98e2-e6f469d6e1a7","metadata":{"id":"a00d8da6-22b8-42b0-98e2-e6f469d6e1a7"},"source":["## Fine-Tune"]},{"cell_type":"code","execution_count":null,"id":"725742cf-c173-481d-963e-0b063e2b75b6","metadata":{"tags":[],"id":"725742cf-c173-481d-963e-0b063e2b75b6","outputId":"709adcac-cbc3-4549-96fe-92a73d1c6c0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","===================================BUG REPORT===================================\n","Welcome to bitsandbytes. For bug reports, please run\n","\n","python -m bitsandbytes\n","\n"," and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n","================================================================================\n","CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n","CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n","CUDA SETUP: Detected CUDA version 113\n","CUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: /opt/conda did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n","  warn(msg)\n"]}],"source":["from transformers import TrainingArguments, Trainer\n","import wandb"]},{"cell_type":"code","execution_count":null,"id":"397552ca-b683-46b9-a7d8-4686913808d8","metadata":{"tags":[],"id":"397552ca-b683-46b9-a7d8-4686913808d8","outputId":"ce26dc11-6368-416d-efe2-b7ece6f7760f","colab":{"referenced_widgets":["","da23b5cf8755450c974a5ff828ea69b5"]}},"outputs":[{"data":{"text/html":["Finishing last run (ID:69rlspv6) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.026 MB of 0.026 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">dauntless-paper-36</strong> at: <a href='https://wandb.ai/mariafshan/MLOps_OPT_125_v1/runs/69rlspv6' target=\"_blank\">https://wandb.ai/mariafshan/MLOps_OPT_125_v1/runs/69rlspv6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20231204_011015-69rlspv6/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:69rlspv6). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da23b5cf8755450c974a5ff828ea69b5","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113334044441418, max=1.0…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/jupyter/Data/wandb/run-20231204_011041-uzo10br5</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/mariafshan/MLOps_OPT_125_v1/runs/uzo10br5' target=\"_blank\">silvery-sponge-37</a></strong> to <a href='https://wandb.ai/mariafshan/MLOps_OPT_125_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/mariafshan/MLOps_OPT_125_v1' target=\"_blank\">https://wandb.ai/mariafshan/MLOps_OPT_125_v1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/mariafshan/MLOps_OPT_125_v1/runs/uzo10br5' target=\"_blank\">https://wandb.ai/mariafshan/MLOps_OPT_125_v1/runs/uzo10br5</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1200/1200 37:43, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>1.039800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.407200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/plain":["TrainOutput(global_step=1200, training_loss=0.6470496114095052, metrics={'train_runtime': 2265.8896, 'train_samples_per_second': 26.465, 'train_steps_per_second': 0.53, 'total_flos': 7834449641472000.0, 'train_loss': 0.6470496114095052, 'epoch': 3.0})"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["training_args = TrainingArguments(\n","    output_dir=\"model/result/\",\n","    push_to_hub=False,\n","    evaluation_strategy = \"no\",\n","    use_cpu = False,\n","    per_device_train_batch_size = 25, # i want to speed up the training\n","    learning_rate = 2e-4\n",")\n","\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    project = \"MLOps_OPT_125_v1\",\n","\n","    # track hyperparameters and run metadata\n","    config = training_args\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset = train_data,\n","    eval_dataset = validation_data,\n","    data_collator = data_collator\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"3c207312-1394-4e0d-b8f3-4e65acec5316","metadata":{"tags":[],"id":"3c207312-1394-4e0d-b8f3-4e65acec5316","outputId":"ac028767-0906-45f1-b0a1-8362608538c1","colab":{"referenced_widgets":[""]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▆█</td></tr><tr><td>train/global_step</td><td>▁▆█</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>1200</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.4072</td></tr><tr><td>train/total_flos</td><td>7834449641472000.0</td></tr><tr><td>train/train_loss</td><td>0.64705</td></tr><tr><td>train/train_runtime</td><td>2265.8896</td></tr><tr><td>train/train_samples_per_second</td><td>26.465</td></tr><tr><td>train/train_steps_per_second</td><td>0.53</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">silvery-sponge-37</strong> at: <a href='https://wandb.ai/mariafshan/MLOps_OPT_125_v1/runs/uzo10br5' target=\"_blank\">https://wandb.ai/mariafshan/MLOps_OPT_125_v1/runs/uzo10br5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20231204_011041-uzo10br5/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["new_model_name = \"model/opt_125_data_v1\"\n","\n","# trainer.model.save_pretrained(new_model_name)\n","trainer.save_model(new_model_name)\n","wandb.finish()"]},{"cell_type":"markdown","id":"142a9f4d-a9df-4f99-920e-97647d1f6c95","metadata":{"id":"142a9f4d-a9df-4f99-920e-97647d1f6c95"},"source":["# Test the New Model"]},{"cell_type":"code","execution_count":null,"id":"0395e6b8-28cd-4dc5-9412-39b4e2bc87ec","metadata":{"tags":[],"id":"0395e6b8-28cd-4dc5-9412-39b4e2bc87ec"},"outputs":[],"source":["new_model_name = \"model/opt_125_data_v1\"\n","\n","new_model = AutoModelForCausalLM.from_pretrained(new_model_name)\n","new_model.config.use_cache = False"]},{"cell_type":"code","execution_count":null,"id":"bda4c0a9-f587-4b71-a270-73b1452267ea","metadata":{"tags":[],"id":"bda4c0a9-f587-4b71-a270-73b1452267ea"},"outputs":[],"source":["def inference(text, model, tokenizer, max_input_tokens = 1000, max_output_tokens = 100):\n","    device = model.device\n","    # Tokenize\n","    input_ids = tokenizer.encode(text, return_tensors=\"pt\", truncation=True, max_length=max_input_tokens).to(device)\n","\n","    # Generate\n","    generated_tokens = model.generate(input_ids=input_ids.to(device), max_length=max_output_tokens, temperature = 0.4, pad_token_id=tokenizer.eos_token_id, do_sample = True)\n","\n","    # Decode\n","    generated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n","\n","    # Strip the prompt\n","    generated_text_answer = generated_text[0][len(text):]\n","\n","    return generated_text_answer\n","\n","def qa_gen(text, model, tokenizer, max_output_tokens = 100):\n","    # instruction = \"instruction: please answer the following question\\n\"\n","    question = \"question: \" + str(text) + \"\\n\"\n","    prompt = question + \"answer:\"\n","    print(prompt)\n","    print(\"-------------------BELOW IS GENERATED BY LANGUAGE MODEL---------------------------\")\n","    print(inference(text = prompt, model = model, tokenizer = tokenizer, max_output_tokens = max_output_tokens))\n","    print(\"-------------------END OF TEXT GENERATED BY LANGUAGE MODEL------------------------\")"]},{"cell_type":"markdown","id":"cb3a2a07-6bac-437e-900d-9a9dd1c923e3","metadata":{"id":"cb3a2a07-6bac-437e-900d-9a9dd1c923e3"},"source":["## Zero-Shot"]},{"cell_type":"code","execution_count":null,"id":"646dc16e-d009-4584-b98b-a15c553c1980","metadata":{"tags":[],"id":"646dc16e-d009-4584-b98b-a15c553c1980","outputId":"68b5dbbd-cc9a-4387-fb60-176c75a48d57"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 14 µs, sys: 4 µs, total: 18 µs\n","Wall time: 23.1 µs\n"]},{"data":{"text/plain":["'What types of exercise are best for people with asthma?'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","\n","test_prompt = [\"What types of exercise are best for people with asthma?\", \"How is obsessive-compulsive disorder diagnosed?\", \"When are you more likely to get a blood clot?\", \"How should you lift objects to prevent back pain?\", \"How can you be smart with antibiotics?\"]\n","\n","test_prompt[0]"]},{"cell_type":"code","execution_count":null,"id":"26f4d085-0285-4893-8b26-ac9d4fe356aa","metadata":{"tags":[],"id":"26f4d085-0285-4893-8b26-ac9d4fe356aa","outputId":"4e7c196e-357a-45d0-9eb0-77cc8ddb276f"},"outputs":[{"name":"stdout","output_type":"stream","text":["question: What types of exercise are best for people with asthma?\n","answer:\n","-------------------BELOW IS GENERATED BY LANGUAGE MODEL---------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1554: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":[" If you're allergic to one type of exercise, you may want to avoid it because it raises your risk of allergies. Exercise may also cause your symptoms. You can help prevent your allergies with medications, home remedies, and other simple things. The best thing you can do is to avoid these triggers. They can make you more likely to get allergies. Talk to your doctor about what you can do to avoid them.\n","-------------------END OF TEXT GENERATED BY LANGUAGE MODEL------------------------\n","\n","question: How is obsessive-compulsive disorder diagnosed?\n","answer:\n","-------------------BELOW IS GENERATED BY LANGUAGE MODEL---------------------------\n"," Your doctor will help you know. But you may not know that you have it because you're not actually diagnosed.\n","\n","    ### Context information is below:\n","    If you have obsessive compulsive disorder ( OCD), you may have noticed that certain things, especially things like eating too much sugar or having certain behaviors, make you more likely to have an episode of obsessive compulsive disorder ( OCD). With OCD\n","-------------------END OF TEXT GENERATED BY LANGUAGE MODEL------------------------\n","\n","question: When are you more likely to get a blood clot?\n","answer:\n","-------------------BELOW IS GENERATED BY LANGUAGE MODEL---------------------------\n"," You're more likely to get a blood clot when you're in the middle of it. If you have a weak immune system, it can make your body attack the clot and get rid of it. But some people don't respond to certain medications the right way. You could have other health problems that make it harder for you to take the medicine. Your doctor may suggest you try a drug called an anti-inflammatory\n","-------------------END OF TEXT GENERATED BY LANGUAGE MODEL------------------------\n","\n","question: How should you lift objects to prevent back pain?\n","answer:\n","-------------------BELOW IS GENERATED BY LANGUAGE MODEL---------------------------\n"," If you can't lift it yet, you should try to get it back to normal. If you can't get it done, you may be tempted to try to do something else, like walking or swimming. Or maybe eating a big or greasy meal. That's not too hard to plan. The first step is to know what's happening and what it is. This is called a \"peripheral vascular disease\n","-------------------END OF TEXT GENERATED BY LANGUAGE MODEL------------------------\n","\n","question: How can you be smart with antibiotics?\n","answer:\n","-------------------BELOW IS GENERATED BY LANGUAGE MODEL---------------------------\n"," How can you tell the difference?\n","\n","    ### Context information is below:\n","    If you're looking for the culprit of the throbbing pain in your head, you may want to jot down the names of the medicines you take. All medications have side effects, and sometimes a headache is one of them. A wide variety of medicines, including birth control pills, heart drugs, and even pain relief medications\n","-------------------END OF TEXT GENERATED BY LANGUAGE MODEL------------------------\n","\n"]}],"source":["for prompt in test_prompt:\n","    qa_gen(text = prompt, model = model, tokenizer = tokenizer, max_output_tokens = 100)\n","    print()"]}],"metadata":{"environment":{"kernel":"python3","name":".m113","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/:m113"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}